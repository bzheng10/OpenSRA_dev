{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLogging(level,file=None):\n",
    "    \"\"\"\n",
    "    This method set the logging level and the format of the logs\n",
    "    \"\"\"\n",
    "    \n",
    "    ## setting logging level\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG if level == 'debug' else logging.INFO)\n",
    "\n",
    "    ## setting log format for print\n",
    "    handlerStream = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handlerStream.setFormatter(formatter)\n",
    "    logger.addHandler(handlerStream)\n",
    "    \n",
    "    ## setting log format for save\n",
    "    if file is not None:\n",
    "        handlerFile = logging.FileHandler(file, mode='w')\n",
    "#         formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handlerFile.setFormatter(formatter)\n",
    "        logger.addHandler(handlerFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## required packages\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os, time\n",
    "import importlib\n",
    "import im.fcn_im as fcn_im\n",
    "import pandas as pd\n",
    "# from numpy.random import standard_normal\n",
    "# from scipy.linalg import cholesky\n",
    "import model, fcn_gen, os, time, warnings\n",
    "from scipy import sparse\n",
    "\n",
    "## setting logging level (e.g. DEBUG or INFO)\n",
    "import logging\n",
    "# from setLogging import *\n",
    "setLogging('info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 16:41:59,446 - root - INFO - Samples exist: 4 IM samples - will not perform sampling.\n",
      "2020-06-30 16:41:59,450 - root - INFO - Number of PGD samples = 4 (for lateral spreading and settlement only).\n",
      "2020-06-30 16:41:59,453 - root - INFO - Defined base directories and paths to required input files.\n",
      "2020-06-30 16:41:59,454 - root - INFO - Damage outputs will be stored in C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites\\dm_resource\\damages\\repair_rates_4samp.\n",
      "2020-06-30 16:41:59,473 - root - INFO - The number of groups to run = 1977.\n"
     ]
    }
   ],
   "source": [
    "## define number of realizations and generate samples\n",
    "flag_sample_exist = True\n",
    "nsamp_im = 4\n",
    "nsamp_pgd = 4\n",
    "flag_corr_d = False\n",
    "flag_corr_T = False\n",
    "if flag_sample_exist:\n",
    "    logging.info(f\"Samples exist: {nsamp_im} IM samples - will not perform sampling.\")\n",
    "else:\n",
    "    logging.info(f\"Number of IM samples = {nsamp_im}; spatial correlation = {flag_corr_d} and cross-correlation = {flag_corr_T}.\")\n",
    "logging.info(f\"Number of PGD samples = {nsamp_pgd} (for lateral spreading and settlement only).\")\n",
    "\n",
    "## base inputs\n",
    "base_dir = r'C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites' # base directory with input files and sub-directories\n",
    "site_loc_file  = os.path.join(base_dir,'CA_pipe_midpt_allsites.txt')\n",
    "im_tool = 'sha'\n",
    "gm_dir = os.path.join(base_dir,'gm_10000yr_allsites_ask14_10samp')\n",
    "im_dir = os.path.join(base_dir,'gm_10000yr_allsites_ask14_'+str(nsamp_im)+'samp')\n",
    "# im_dir = os.path.join(base_dir,'gm_10000yr_allsites_ask14_'+str(nsamp_im)+'samp_pgv_const_sigma')\n",
    "dm_dir = os.path.join(base_dir,'dm_resource','damages','repair_rates_'+str(nsamp_im)+'samp')\n",
    "rup_meta_file = os.path.join(base_dir,'rup_meta_10000yr.hdf5')\n",
    "l_seg_file = os.path.join(base_dir,'seg_length_allsites.txt')\n",
    "logging.info(f\"Defined base directories and paths to required input files.\")\n",
    "logging.info(f\"Damage outputs will be stored in {dm_dir}.\")\n",
    "\n",
    "## number of groups\n",
    "groups2run = np.loadtxt(os.path.join(base_dir,'groups2run_allsites.txt'),dtype=str)\n",
    "rup_per_group = 100\n",
    "multi_max = int(np.ceil(len(groups2run)/rup_per_group))\n",
    "logging.info(f\"The number of groups to run = {len(groups2run)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 16:44:11,070 - root - INFO - Load/reloaded \"model.py\".\n",
      "2020-06-30 16:44:11,093 - root - INFO - Created model class object named \"A\".\n",
      "2020-06-30 16:44:11,094 - root - INFO - Damages include: ['rr_pgd']. Demands include: ['land'].\n",
      "2020-06-30 16:44:11,095 - root - INFO - Samples are will be imported.\n",
      "2020-06-30 16:44:11,096 - root - INFO - Flag for probability of liquefaction = False.\n",
      "2020-06-30 16:44:11,097 - root - INFO - Flag for liquefaction susceptibility = False.\n",
      "2020-06-30 16:44:11,098 - root - INFO - Flag for probability of landslide = True.\n",
      "2020-06-30 16:44:11,102 - root - INFO - Will print messages every 5 groups (each group contains 100 ruptures).\n",
      "2020-06-30 16:44:11,104 - root - INFO - Will save damage outputs every 100 groups (each group contains 100 ruptures).\n",
      "2020-06-30 16:44:11,585 - root - INFO - Imported site parameters for landslide-induced demands.\n"
     ]
    }
   ],
   "source": [
    "## reload model.py if it has been modified\n",
    "importlib.reload(model)\n",
    "logging.info(f'Load/reloaded \"model.py\".')\n",
    "\n",
    "## create class object\n",
    "A = model.assessment()\n",
    "logging.info(f'Created model class object named \"A\".')\n",
    "\n",
    "## cases to run\n",
    "dmgs = ['rr_pgd'] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "# dmg_procs = ['hazus','ala','orourke'] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "dmg_procs = ['orourke'] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "dmds = ['land'] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "ims = ['pga','pgv'] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "## for sampling\n",
    "# dmgs = [] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "# dmg_procs = [] # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "# dmds = []\n",
    "# ims = ['pgv']\n",
    "\n",
    "if 'rr_pgv' in dmgs and len(dmgs) == 1:\n",
    "    dmds = []\n",
    "    ims = ['pgv']\n",
    "logging.info(f\"Damages include: {dmgs}. Demands include: {dmds if len(dmds) > 0 else None}.\")\n",
    "\n",
    "## decide if samples are needed\n",
    "flag_gen_sample = False\n",
    "if flag_sample_exist:\n",
    "    flag_gen_sample = True\n",
    "flag_get_IM = False # default to False\n",
    "if 'rr_pgv' in dmgs:\n",
    "    flag_get_IM = True\n",
    "if 'rr_pgd' in dmgs:\n",
    "    if 'hazus' in dmg_procs:\n",
    "        flag_get_IM = True\n",
    "    else:\n",
    "        if 'ls' in dmds or 'land' in dmds or 'surf' in dmds:\n",
    "            flag_get_IM = True\n",
    "if flag_get_IM:\n",
    "    logging.info(f\"Samples are will be imported.\")\n",
    "else:\n",
    "    logging.info(f\"Samples are not needed.\")\n",
    "\n",
    "## check if probability of liquefaction is needed\n",
    "if 'rr_pgd' in dmgs and ('ls' in dmds or 'gs' in dmds):\n",
    "    flag_p_liq = True\n",
    "else:\n",
    "    flag_p_liq = False\n",
    "logging.info(f\"Flag for probability of liquefaction = {flag_p_liq}.\")\n",
    "    \n",
    "## check if liquefaction susceptibility is needed\n",
    "if 'rr_pgd' in dmgs and ('ls' in dmds or 'gs' in dmds):\n",
    "    flag_liq_susc = True\n",
    "else:\n",
    "    flag_liq_susc = False\n",
    "logging.info(f\"Flag for liquefaction susceptibility = {flag_liq_susc}.\")\n",
    "\n",
    "## check if probability of landslide is needed\n",
    "if 'rr_pgd' in dmgs and 'land' in dmds:\n",
    "    flag_p_land = True\n",
    "else:\n",
    "    flag_p_land = False\n",
    "logging.info(f\"Flag for probability of landslide = {flag_p_land}.\")\n",
    "\n",
    "## increment to print output messages\n",
    "flag_save_dmg = True # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "if len(dmgs) == 0:\n",
    "\tflag_save_dmg = False\n",
    "if flag_get_IM or flag_gen_sample:\n",
    "    inc1 = 5 # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "#     inc2 = rup_per_group # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    inc2 = 100 # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "    logging.info(f\"Will print messages every {inc1} groups (each group contains {rup_per_group} ruptures).\")\n",
    "if flag_save_dmg:\n",
    "    logging.info(f\"Will save damage outputs every {inc2} groups (each group contains {rup_per_group} ruptures).\")\n",
    "else:\n",
    "    logging.info(f\"Damage outputs will not be saved.\")\n",
    "\n",
    "## Load site params depending on demands needed\n",
    "if flag_liq_susc or flag_p_liq or ('rr_pgd' in dmgs and 'land' in dmds):\n",
    "    \n",
    "    ## read inputs for Zhu et al. (2017)\n",
    "    zhu_inputs = pd.read_csv(os.path.join(base_dir,'CA_Zhu_pipe_midpt_allsites_withWB_v2_remap.csv'))\n",
    "    \n",
    "    ## for liquefaction-induced demands\n",
    "    if flag_liq_susc or flag_p_liq:\n",
    "        \n",
    "        ## import general inputs\n",
    "        wtd = zhu_inputs['WTD_30m (m)'].values\n",
    "        dr = zhu_inputs['DistRivers (km)'].values\n",
    "        dc = zhu_inputs['DistCoast (km)'].values\n",
    "        dw = zhu_inputs['DistAnyWaterNoWB (km)'].values\n",
    "        precip = zhu_inputs['CA_Precip (mm)'].values\n",
    "        vs30 = zhu_inputs['vs30_opensha (m/s)'].values\n",
    "        \n",
    "        ## change all -9999 entries to NaN\n",
    "        find_val = -9999\n",
    "        set_val = np.nan\n",
    "        wtd = fcn_gen.find_set_nan(wtd,find_val,set_val)\n",
    "        dr = fcn_gen.find_set_nan(dr,find_val,set_val)\n",
    "        dc = fcn_gen.find_set_nan(dc,find_val,set_val)\n",
    "        dw = fcn_gen.find_set_nan(dw,find_val,set_val)\n",
    "        precip = fcn_gen.find_set_nan(precip,find_val,set_val)\n",
    "        vs30 = fcn_gen.find_set_nan(vs30,find_val,set_val)\n",
    "        \n",
    "        ## elevation from DEM maps\n",
    "        z = np.ones(vs30.shape)*10 ## set to 10 for now, get data from DEM map later\n",
    "\n",
    "        ## for ground settlement\n",
    "        if 'ls' in dmds:\n",
    "            dwWB = zhu_inputs['DistAnyWaterWB (km)'].values\n",
    "            dwWB = fcn_gen.find_set_nan(dwWB,find_val,set_val)\n",
    "            dwWB = dwWB*1000 # convert to meters\n",
    "\n",
    "        logging.info(f\"Imported site parameters for liquefaction-induced demands.\")\n",
    "        \n",
    "    ## for landslide-induced demands\n",
    "    if 'land' in dmds:\n",
    "        ky = zhu_inputs['ky_inf_bray'].values\n",
    "#         ky[ky==0] = 0.0001\n",
    "        logging.info(f\"Imported site parameters for landslide-induced demands.\")\n",
    "    \n",
    "if 'surf' in dmds:\n",
    "    intersect_dir = os.path.join(base_dir,'gm_resource','rup_intersect')\n",
    "    logging.info(f\"Defined directory with fault crossings: {intersect_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 16:44:11,677 - root - INFO - Multiplers to run: 0 to 0.\n",
      "2020-06-30 16:44:11,679 - root - INFO - Count = 1: rupture group = 0_99...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6225752966509351\n",
      "0.6225752966509351\n",
      "0.6225752966509351\n",
      "0.6225752966509351\n",
      "-1.2209999999999999\n",
      "0.0\n",
      "1.2209999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-30 16:44:30,003 - root - INFO - ...done with current set\n"
     ]
    }
   ],
   "source": [
    "## define multiplier; grops to run = multiplier * rup_per_group\n",
    "multi_start = 0\n",
    "n_multi = 1 # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "if flag_get_IM or flag_gen_sample:\n",
    "    multi_end = multi_start+n_multi\n",
    "    logging.info(f\"Multiplers to run: {multi_start} to {multi_end-1}.\")\n",
    "else:\n",
    "    multi_end = multi_start+1\n",
    "    logging.info(f\"Samples not needed, no need to loop multi.\")\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "## loop through multipliers\n",
    "for multi in range(multi_start,multi_end):\n",
    "    \n",
    "    ## define range of ruptures for IM\n",
    "    range_start = rup_per_group*multi\n",
    "    if flag_get_IM or flag_gen_sample:\n",
    "#         range_end = range_start+rup_per_group\n",
    "        range_end = range_start+1\n",
    "        logging.debug(f\"Multi {multi}...\")\n",
    "    else:\n",
    "        range_end = range_start+1\n",
    "    count = range_start\n",
    "\n",
    "    ## loop through groups\n",
    "    for rup_group in groups2run[range_start:range_end]:\n",
    "        count += 1\n",
    "        count_EDP = 0\n",
    "        logging.info(f'Count = {count}: rupture group = {rup_group}...')\n",
    "        \n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "        logging.debug(f\"-------------Intensity Measures-------------\")\n",
    "        #####################################################################\n",
    "        ## load GM predictions and create random variable\n",
    "        A.create_RV(im_tool, gm_dir, ims, rup_meta_file, site_loc_file, l_seg_file=l_seg_file, \n",
    "                    flag_clear_dict=True, flag_sample_exist=flag_sample_exist, rup_group=rup_group)\n",
    "        logging.debug(f'\\tIM_rv: Updated \"_RV_dict\".')\n",
    "        \n",
    "        #####################################################################\n",
    "        ## generate/import samples\n",
    "        if flag_get_IM or flag_gen_sample:\n",
    "            path_sample = os.path.join(im_dir,rup_group)\n",
    "            flag_sample_with_sigma_total = True\n",
    "            sigma_aleatory = 0.400\n",
    "            n_decimals = 3\n",
    "            A.get_IM(nsamp_im, ims, flag_corr_d, flag_corr_T, \n",
    "                     flag_sample_with_sigma_total=flag_sample_with_sigma_total,\n",
    "                     sigma_aleatory=sigma_aleatory,\n",
    "                     flag_clear_dict=True, flag_sample_exist=flag_sample_exist,\n",
    "                     path_sample=path_sample)\n",
    "            if flag_sample_exist:\n",
    "                logging.debug(f'\\tIM_sim: Updated \"_IM_dict\" using path to samples = {path_sample}.')\n",
    "            else:\n",
    "                if not os.path.isdir(os.path.join(im_dir,rup_group)):\n",
    "                    os.mkdir(os.path.join(im_dir,rup_group))\n",
    "                for im in ims:\n",
    "                    for samp_i in range(nsamp_im):\n",
    "                        sparse_mat = A._IM_dict[im][samp_i].log1p().tocsc()\n",
    "                        sparse_mat.data = np.round(sparse_mat.data,decimals=n_decimals)\n",
    "                        sparse.save_npz(os.path.join(im_dir,rup_group,'pgv_samp_'+str(samp_i)+'.npz'),sparse_mat)\n",
    "                logging.debug(f'\\tIM_sim: Updated \"_IM_dict\" by sampling.')\n",
    "\n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "        logging.debug(f\"-------------Engineering Demand Parameters-------------\")\n",
    "        #####################################################################\n",
    "        if flag_p_liq or flag_liq_susc:\n",
    "            count_EDP += 1\n",
    "            ## use Zhu et al. (2017)\n",
    "            category = 'liq'\n",
    "            method = 'zhu_etal_2017'\n",
    "            return_param = []\n",
    "            if flag_p_liq:\n",
    "                return_param.append('p_liq')\n",
    "            if flag_liq_susc:\n",
    "                return_param.append('liq_susc')\n",
    "            logging.debug(f'\\tReturn params = {return_param}.')\n",
    "            flag_pgv = True\n",
    "            flag_M = True\n",
    "            dc_cutoff = 20\n",
    "            flag_clear_dict = True if count_EDP == 1 else False\n",
    "#             logging.debug(f\"LIQ: count_EDP = {count_EDP}, flag_clear_dict = {flag_clear_dict}\")\n",
    "            logging.debug(f'\\tEDP_liq: Calculate \"{return_param}\" using \"{method}\".')\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                A.get_EDP(category=category, method=method, return_param=return_param,\n",
    "                          flag_clear_dict=flag_clear_dict, flag_pgv=flag_pgv, flag_M=flag_M, \n",
    "                          vs30=vs30, precip=precip, dc=dc, dr=dr, dw=dw, \n",
    "                          wtd=wtd, dc_cutoff=dc_cutoff, nsamp_im=nsamp_im)\n",
    "\n",
    "        #####################################################################\n",
    "        if 'ls' in dmds:\n",
    "            count_EDP += 1\n",
    "            ## get pgd_ls from Grant et al. (2016), same as HAZUS (FEMA, 2014)\n",
    "            category = 'ls'\n",
    "            method = 'hazus_2014_ls'\n",
    "            return_param = ['pgd_ls']\n",
    "            source_dict = ['_EDP_dict']\n",
    "            source_param = ['liq_susc']\n",
    "            source_method = ['zhu_etal_2017']\n",
    "            flag_pga = True\n",
    "            flag_M = True\n",
    "            dw_cutoff = 50\n",
    "            flag_clear_dict = True if count_EDP == 1 else False\n",
    "            eps_aleatory = np.ones(nsamp_pgd)\n",
    "            wgt_aleatory = np.ones(nsamp_pgd)/nsamp_pgd\n",
    "            eps_epistemic = [-1,1]\n",
    "            # eps_epistemic = [0]\n",
    "#             logging.debug(f\"LS: count_EDP = {count_EDP}, flag_clear_dict = {flag_clear_dict}\")\n",
    "            logging.debug(f'\\tEDP_ls: Calculate \"{return_param}\" using \"{method}\" and \"{source_param}\" from \"{source_method}\".')\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                A.get_EDP(category=category, method=method, return_param=return_param,\n",
    "                          flag_clear_dict=flag_clear_dict, flag_pga=flag_pga, flag_M=flag_M, \n",
    "                          source_dict=source_dict, source_param=source_param, source_method=source_method, \n",
    "                          dw=dwWB, z=z, nsamp_im=nsamp_im, flag_extrap_Epgd=True, dw_cutoff=dw_cutoff,\n",
    "                          eps_aleatory=eps_aleatory, wgt_aleatory=wgt_aleatory, eps_epistemic=eps_epistemic)\n",
    "         \n",
    "        #####################################################################   \n",
    "        if 'gs' in dmds:\n",
    "            count_EDP += 1\n",
    "            ## get pgd_gs from HAZUS (FEMA, 2014)\n",
    "            category = 'gs'\n",
    "            method = 'hazus_2014_gs'\n",
    "            return_param = ['pgd_gs']\n",
    "            source_dict = ['_EDP_dict']\n",
    "            source_param = ['liq_susc']\n",
    "            source_method = ['zhu_etal_2017']\n",
    "            flag_clear_dict = True if count_EDP == 1 else False\n",
    "            eps_aleatory = np.ones(nsamp_pgd)\n",
    "            wgt_aleatory = np.ones(nsamp_pgd)/nsamp_pgd\n",
    "            eps_epistemic = [-1,1]\n",
    "            # eps_epistemic = [0]\n",
    "#             logging.debug(f\"GS: count_EDP = {count_EDP}, flag_clear_dict = {flag_clear_dict}\")\n",
    "            logging.debug(f'\\tEDP_gs: Calculate \"{return_param}\" using \"{method}\" and \"{source_param}\" from \"{source_method}\".')\n",
    "            A.get_EDP(category=category, method=method, return_param=return_param, \n",
    "                      flag_clear_dict=flag_clear_dict, \n",
    "                      source_dict=source_dict, source_param=source_param, source_method=source_method,\n",
    "                      eps_aleatory=eps_aleatory, wgt_aleatory=wgt_aleatory, eps_epistemic=eps_epistemic)\n",
    "            \n",
    "        #####################################################################              \n",
    "        if 'land' in dmds:\n",
    "            count_EDP += 1\n",
    "            ## get pgd_ls from Grant et al. (2016), same as HAZUS (FEMA, 2014)\n",
    "            category = 'land'\n",
    "            method = 'bray_macedo_2019'\n",
    "            return_param = ['pgd_land']\n",
    "            if flag_p_land:\n",
    "                return_param.append('p_land')\n",
    "            logging.debug(f'\\tReturn params = {return_param}.')\n",
    "            gm_type = 'general'\n",
    "            flag_pgv = True\n",
    "            flag_pga = True\n",
    "            flag_M = True\n",
    "            flag_clear_dict = True if count_EDP == 1 else False\n",
    "            eps_aleatory = [-1.65,0,1.65]\n",
    "            wgt_aleatory = [0.2,0.6,0.2]\n",
    "            eps_epistemic = [-1.65,0,1.65]\n",
    "#             eps_epistemic = [999]\n",
    "#             logging.debug(f\"LAND: count_EDP = {count_EDP}, flag_clear_dict = {flag_clear_dict}\")\n",
    "            logging.debug(f'\\tEDP_land: Calculate \"{return_param}\" using \"{method}\".')\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                A.get_EDP(category=category, method=method, return_param=return_param,\n",
    "                          flag_clear_dict=flag_clear_dict, flag_pga=flag_pga, flag_M=flag_M, flag_pgv=flag_pgv,\n",
    "                          ky=ky, nsamp_im=nsamp_im, gm_type=gm_type,\n",
    "                          eps_aleatory=eps_aleatory, wgt_aleatory=wgt_aleatory, eps_epistemic=eps_epistemic)\n",
    "                        \n",
    "        #####################################################################  \n",
    "        if 'surf' in dmds:\n",
    "            count_EDP += 1\n",
    "            ## set up for surface fault rupture\n",
    "            rows = []\n",
    "            cols = []\n",
    "            dim_rup = len(A._RV_dict['rup']['src'])\n",
    "            dim_d = len(A._rup_site_dict['site_lon'])\n",
    "            count_seg = 0\n",
    "            for src in A._RV_dict['rup']['src']:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    seg_list = np.loadtxt(os.path.join(intersect_dir,'src_'+str(src)+'.txt'),dtype=int,ndmin=1)\n",
    "                for seg in seg_list:\n",
    "                    rows.append(count_seg)\n",
    "                    cols.append(seg)\n",
    "                count_seg += 1\n",
    "            rows = np.asarray(rows)\n",
    "            cols = np.asarray(cols)\n",
    "            mat = sparse.coo_matrix((np.ones(len(rows)),(rows,cols)),shape=(dim_rup,dim_d))\n",
    "            logging.debug(f'\\tEDP_surf: Generated matrix of flags for fault crossing.')\n",
    "            \n",
    "            #####################################################################\n",
    "            ## pgd_surf from Wells and coppersmith (1994), with Steve Thompson's coefficients\n",
    "            category = 'surf'\n",
    "            method = 'wells_coppersmith_1994'\n",
    "            return_param = ['pgd_surf']\n",
    "            flag_M = True\n",
    "            flag_clear_dict = True if count_EDP == 1 else False\n",
    "            eps_aleatory = [-1.65,0,1.65]\n",
    "            wgt_aleatory = [0.2,0.6,0.2]\n",
    "#             eps_epistemic = [999,-1.65,0,1.65]\n",
    "            eps_epistemic = [999]\n",
    "#             logging.debug(f\"SURF: count_EDP = {count_EDP}, flag_clear_dict = {flag_clear_dict}\")\n",
    "            logging.debug(f'\\tEDP_surf: Calculate \"{return_param}\" using \"{method}\".')\n",
    "            logging.debug(f\"epsilons for aleatory variability = {eps_aleatory}, epsilons for epistemic uncertainty = {eps_epistemic} (if 999, then use lumped sigma).\")\n",
    "            A.get_EDP(category=category, method=method, return_param=return_param, \n",
    "                      flag_clear_dict=flag_clear_dict, flag_M=flag_M, mat_seg2calc=mat,\n",
    "                      eps_aleatory=eps_aleatory, wgt_aleatory=wgt_aleatory, eps_epistemic=eps_epistemic)\n",
    "\n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "        logging.debug(f\"-------------Damage Measures-------------\")\n",
    "        #####################################################################\n",
    "        category = 'rr'\n",
    "        if 'rr_pgv' in dmgs:\n",
    "            return_param = ['rr_pgv']\n",
    "            flag_pgv = True\n",
    "            eps_epistemic = [-1.65,0,1.65]\n",
    "            sigma_epistemic = 0.65\n",
    "            for proc_i in dmg_procs:\n",
    "                ## set damage label\n",
    "                if 'hazus' in proc_i:\n",
    "                    method = proc_i+'_2014'+'_rr'\n",
    "                    flag_orourke_pgv = False\n",
    "                elif 'ala' in proc_i:\n",
    "                    method = proc_i+'_2001'+'_rr'\n",
    "                    flag_orourke_pgv = False\n",
    "                elif 'orourke' in proc_i:\n",
    "                    method = proc_i+'_2020'+'_rr'\n",
    "                    flag_orourke_pgv = True\n",
    "                else:\n",
    "                    method = None\n",
    "                    logging.info(\"procedure does not exist...exiting\")\n",
    "                \n",
    "                ## set method name and run calculation\n",
    "                logging.debug(f'\\tDM_rr_pgv: Calculate \"{return_param}\" using \"{method}\".')\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    A.get_DM(category, method, return_param, ims,\n",
    "                             flag_pgv=flag_pgv, nsamp_im=nsamp_im, flag_orourke_pgv=flag_orourke_pgv,\n",
    "\t\t\t\t\t\t\t eps_epistemic=eps_epistemic, sigma_epistemic=sigma_epistemic)\n",
    "        \n",
    "        #####################################################################\n",
    "        if 'rr_pgd' in dmgs:\n",
    "            return_param = ['rr_pgd']\n",
    "            flag_rup_depend = True\n",
    "            flag_proc_repeat = False\n",
    "            for proc_i in dmg_procs:\n",
    "                ## set damage label\n",
    "                if 'hazus' in proc_i:\n",
    "                    method = proc_i+'_2014'+'_rr'\n",
    "                    pgd_cutoff = 0\n",
    "                elif 'ala' in proc_i:\n",
    "                    method = proc_i+'_2001'+'_rr'\n",
    "                    pgd_cutoff = 0\n",
    "                elif 'orourke' in proc_i:\n",
    "                    method = proc_i+'_2020'+'_rr'\n",
    "                    pgd_cutoff = 4*2.54\n",
    "                else:\n",
    "                    method = None\n",
    "                    logging.info(\"procedure does not exist...exiting\")\n",
    "\n",
    "                ## set method name and loop through all pgd demands\n",
    "                for dmd_i in dmds:\n",
    "                    ## initialize lists\n",
    "                    source_dict = ['_EDP_dict']\n",
    "                    source_param = []\n",
    "                    source_method = []\n",
    "                    ##\n",
    "                    pgd_label = 'pgd_'+dmd_i\n",
    "                    source_param.append(pgd_label)\n",
    "                    if 'ls' in dmd_i or 'gs' in dmd_i:\n",
    "                        source_method.append('hazus_2014_'+dmd_i)\n",
    "                        source_dict.append('_EDP_dict')\n",
    "                        source_param.append('p_liq')\n",
    "                        source_method.append('zhu_etal_2017')\n",
    "                    elif 'land' in dmd_i:\n",
    "                        source_method.append('bray_macedo_2019')\n",
    "                        source_dict.append('_EDP_dict')\n",
    "                        source_param.append('p_land')\n",
    "                        source_method.append('bray_macedo_2019')\n",
    "                    elif 'surf' in dmd_i:\n",
    "                        source_method.append('wells_coppersmith_1994')\n",
    "                    logging.debug(f'\\tDM_rr_pgd: Calculate \"{return_param}\" using \"{method}\" and \"{source_param}\" from \"{source_method}\".')\n",
    "                    with warnings.catch_warnings():\n",
    "                        warnings.simplefilter(\"ignore\")\n",
    "                        A.get_DM(category=category, method=method, return_param=return_param, \n",
    "                                 flag_rup_depend=flag_rup_depend,\n",
    "                                 source_dict=source_dict, source_param=source_param, source_method=source_method, \n",
    "                                 nsamp_im=nsamp_im, pgd_cutoff=pgd_cutoff, pgd_label=pgd_label)\n",
    "\n",
    "    \n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "        if (flag_get_IM or flag_gen_sample) and count % inc1 == 0:\n",
    "                logging.info(f\"-------------After {count*rup_per_group} groups: {np.round(time.time()-time_start,decimals=2)} secs-------------\")\n",
    "                time_start = time.time()\n",
    "        \n",
    "        #####################################################################\n",
    "        #####################################################################\n",
    "#         if flag_save_dmg:\n",
    "#             if count % inc2 == 0 or count == len(groups2run):\n",
    "#                 logging.info(f\"\\tSaving damages...\")\n",
    "#                 for dmg_i in A._DM_dict.keys():\n",
    "#                     count_proc = 0\n",
    "#                     for proc_i in A._DM_dict[dmg_i].keys():\n",
    "#                         if 'rr_pgd' in dmg_i:\n",
    "#                             for i in A._DM_dict[dmg_i][proc_i]['source_param']:\n",
    "#                                 if 'pgd' in i:\n",
    "#                                     dmd_i = i\n",
    "#                             str_dmd_i = dmd_i[dmd_i.find('_')+1:]+'_'\n",
    "#                         else:\n",
    "#                             str_dmd_i = ''\n",
    "#                         str_proc_i = A._DM_dict[dmg_i][proc_i]['method'][0:A._DM_dict[dmg_i][proc_i]['method'].find('_')]\n",
    "#                         if A._DM_dict[dmg_i][proc_i]['eps_epistemic'] == 999:\n",
    "#                             str_eps = 'epiTotal_'\n",
    "#                         else:\n",
    "#                             str_eps = 'epi'+str(A._DM_dict[dmg_i][proc_i]['eps_epistemic'])+'_'\n",
    "#                             str_eps = str_eps.replace('.','o')\n",
    "#                             str_eps = str_eps.replace('-','m')\n",
    "#                         str_range = 'rup_'+str(range_start)+'_'+str(range_end-1)\n",
    "#                         save_name = dmg_i+'_'+str_proc_i+'_'+str_dmd_i+str_eps+str_range+'.npz'\n",
    "#                         save_path = os.path.join(dm_dir,save_name)\n",
    "#                         logging.info(f\"\\t\\t{save_name}\")\n",
    "#                         sparse.save_npz(save_path,np.transpose(A._DM_dict[dmg_i][proc_i]['output']))\n",
    "#                         count_proc += 1\n",
    "\n",
    "logging.info(f\"...done with current set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rr_pgd': {'method1': {'method': 'orourke_2020_rr',\n",
       "   'source_param': ['pgd_land', 'p_land'],\n",
       "   'source_method': ['bray_macedo_2019', 'bray_macedo_2019'],\n",
       "   'eps_epistemic': 999,\n",
       "   'eps_aleatory': [-1.65, 0, 1.65],\n",
       "   'wgt_aleatory': [0.2, 0.6, 0.2],\n",
       "   'output': <4x123316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 874 stored elements in Compressed Sparse Column format>},\n",
       "  'method2': {'method': 'orourke_2020_rr',\n",
       "   'source_param': ['pgd_land', 'p_land'],\n",
       "   'source_method': ['bray_macedo_2019', 'bray_macedo_2019'],\n",
       "   'eps_epistemic': -1.65,\n",
       "   'eps_aleatory': [-1.65, 0, 1.65],\n",
       "   'wgt_aleatory': [0.2, 0.6, 0.2],\n",
       "   'output': <4x123316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 395 stored elements in Compressed Sparse Column format>},\n",
       "  'method3': {'method': 'orourke_2020_rr',\n",
       "   'source_param': ['pgd_land', 'p_land'],\n",
       "   'source_method': ['bray_macedo_2019', 'bray_macedo_2019'],\n",
       "   'eps_epistemic': 0,\n",
       "   'eps_aleatory': [-1.65, 0, 1.65],\n",
       "   'wgt_aleatory': [0.2, 0.6, 0.2],\n",
       "   'output': <4x123316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 2037 stored elements in Compressed Sparse Column format>},\n",
       "  'method4': {'method': 'orourke_2020_rr',\n",
       "   'source_param': ['pgd_land', 'p_land'],\n",
       "   'source_method': ['bray_macedo_2019', 'bray_macedo_2019'],\n",
       "   'eps_epistemic': 1.65,\n",
       "   'eps_aleatory': [-1.65, 0, 1.65],\n",
       "   'wgt_aleatory': [0.2, 0.6, 0.2],\n",
       "   'output': <4x123316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "   \twith 8113 stored elements in Compressed Sparse Column format>}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A._DM_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02621234, 0.00236126, 0.01045677, 0.02151469, 0.0194128 ,\n",
       "       0.06489118, 0.91677073, 0.01890516, 0.00099298, 0.04694919,\n",
       "       0.02364384, 0.01459185, 0.02677483, 0.02508768, 0.01740504,\n",
       "       0.01997873, 0.01782076, 0.01424091, 0.03779048, 0.04947491])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A._DM_dict['rr_pgd']['method1']['output'].data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<123316x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 337 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = sparse.load_npz(r'C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites\\dm_resource\\damages\\repair_rates_4samp\\rr_pgd_orourke_surf_epiTotal_rup_0_99_backup.npz')\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02621234, 0.00236126, 0.01045677, 0.02151469, 0.0194128 ,\n",
       "       0.06489118, 0.91677073, 0.01890516, 0.00099298, 0.04694919,\n",
       "       0.02364384, 0.01459185, 0.02677483, 0.02508768, 0.01740504,\n",
       "       0.01997873, 0.01782076, 0.01424091, 0.03779048, 0.04947491])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 12.12770151,  12.43036281, 131.7129635 ,  76.58710194,\n",
       "       149.11434034, 145.39642656, 107.96625098,  81.06869367,\n",
       "        97.66998668, 135.75300673,  62.3896885 ,  99.69343478,\n",
       "        87.85745566,  66.42027574,  13.08470397,  13.58802266,\n",
       "        13.69269546,  17.58731004,   9.7577716 ,   8.4343066 ,\n",
       "        13.64256039,  30.31218441,  12.08779752,  19.20081549,\n",
       "        16.56396997,  29.28259403,  11.88209644,  14.08729928,\n",
       "         6.97421375,   7.87159413,  28.98274397,   9.2686643 ,\n",
       "         5.74758219,  17.23264027,  12.62489099,  14.04128261,\n",
       "         8.51650215,  18.13716207,  14.12790005,   7.95590811,\n",
       "        19.46592814,   6.52120622,  14.22050185,  13.36736222,\n",
       "         8.18214274,  10.3286225 ,  10.26105406,  11.40353888,\n",
       "         9.47924263,  13.79080563,  10.15816901,   8.27031727,\n",
       "         6.50262419,   7.67758614,   9.01232005,   3.85098018,\n",
       "         9.61153064,  11.30484652,   6.42667086,  16.61646662,\n",
       "         7.98977733,  17.85906474,  12.8290343 ,   7.33743459,\n",
       "         6.47622494,   5.0996899 ,   5.78670054,  10.75012616,\n",
       "        14.05685718,  33.90802511,  31.04386545,  25.96040854,\n",
       "        23.72186579,  31.62142258,  20.56856458,  47.10594459,\n",
       "        51.33172809,  23.58269323,  40.93850262,  15.78653969,\n",
       "        31.68766083,  39.11561196,  39.60488978,  74.89511554,\n",
       "        38.20676894,  27.37337472,  31.75042468,  35.80387204,\n",
       "        33.44691678,  47.99896205,  37.95537815, 117.45369687,\n",
       "        43.90341137,  57.70168442,  47.12943615,  21.27554079,\n",
       "        35.3878887 ,  25.85862994,  21.04412621,  39.36919793])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A._IM_dict['pgv'][0].data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = sparse.load_npz(r'C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites\\gm_10000yr_allsites_ask14_4samp\\0_99\\pga_samp_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.046, 0.019, 0.193, 0.024, 0.047, 0.108, 0.074, 0.126, 0.332,\n",
       "       0.154, 0.078, 0.092, 0.071, 0.345, 0.048, 0.16 , 0.016, 0.079,\n",
       "       0.111, 0.068, 0.069, 0.307, 0.255, 0.048, 0.099, 0.029, 0.152,\n",
       "       0.033, 0.137, 0.014, 0.062, 0.121, 0.108, 0.113, 0.16 , 0.191,\n",
       "       0.242, 0.133, 0.024, 0.18 , 0.012, 0.207, 0.043, 0.049, 0.077,\n",
       "       0.055, 0.144, 0.423, 0.172, 0.129, 0.045, 0.022, 0.12 , 0.034,\n",
       "       0.059, 0.026, 0.039, 0.068, 0.061, 0.228, 0.193, 0.199, 0.113,\n",
       "       0.033, 0.094, 0.054, 0.01 , 0.141, 0.023, 0.026, 0.028, 0.059,\n",
       "       0.128, 0.254, 0.722, 0.054, 0.032, 0.017, 0.146, 0.016, 0.143,\n",
       "       0.025, 0.051, 0.125, 0.039, 0.129, 0.29 , 0.191, 0.096, 0.028,\n",
       "       0.027, 0.065, 0.046, 0.11 , 0.006, 0.049, 0.114, 0.082, 0.107,\n",
       "       0.103, 0.959, 0.192, 0.029, 0.018, 0.102, 0.079, 0.035, 0.027,\n",
       "       0.034, 0.05 , 0.052, 0.297, 0.18 , 0.322, 0.072, 0.047, 0.024,\n",
       "       0.022, 0.022, 0.099, 0.017, 0.015, 0.04 , 0.042, 0.097, 0.419,\n",
       "       0.199, 0.144, 0.062, 0.022, 0.193, 0.015, 0.063, 0.035, 0.041,\n",
       "       0.091, 0.039, 0.056, 0.378, 0.74 , 0.057, 0.051, 0.05 , 0.164,\n",
       "       0.038, 0.158, 0.083, 0.04 , 0.099, 0.034, 0.145, 0.199, 0.314,\n",
       "       0.185, 0.032, 0.046, 0.1  , 0.011, 0.155, 0.014, 0.039, 0.04 ,\n",
       "       0.076, 0.1  , 0.32 , 0.21 , 0.099, 0.051, 0.029, 0.122, 0.05 ,\n",
       "       0.09 , 0.02 , 0.022, 0.047, 0.034, 0.392, 0.106, 0.458, 0.033,\n",
       "       0.034, 0.04 , 0.218, 0.04 , 0.087, 0.032, 0.02 , 0.049, 0.097,\n",
       "       0.063, 0.247, 0.116, 0.295, 0.04 , 0.021, 0.386, 0.058, 0.052,\n",
       "       0.043, 0.085, 0.08 , 0.164, 0.144, 0.138, 0.265, 0.115, 0.025,\n",
       "       0.011, 0.095, 0.069, 0.072, 0.035, 0.025, 0.151, 0.043, 0.159,\n",
       "       0.142, 0.371, 0.123, 0.05 , 0.02 , 0.047, 0.016, 0.133, 0.054,\n",
       "       0.024, 0.048, 0.032, 0.042, 0.173, 0.816, 0.43 , 0.088, 0.012,\n",
       "       0.1  , 0.046, 0.06 , 0.01 , 0.059, 0.073, 0.071, 0.07 , 0.285,\n",
       "       0.226, 0.129, 0.032, 0.022, 0.094, 0.006, 0.09 , 0.019, 0.025,\n",
       "       0.13 , 0.124, 0.051, 0.227, 0.212, 0.139, 0.069, 0.018, 0.211,\n",
       "       0.096, 0.064, 0.021, 0.045, 0.036, 0.117, 0.117, 0.342, 0.268,\n",
       "       0.111, 0.016, 0.03 , 0.042, 0.014, 0.256, 0.031, 0.032, 0.309,\n",
       "       0.041, 0.109, 0.226, 0.483, 0.114, 0.033, 0.142, 0.03 , 0.195,\n",
       "       0.016, 0.037, 0.04 , 0.067, 0.166, 0.188, 0.229, 0.094, 0.069,\n",
       "       0.495, 0.026, 0.089, 0.024, 0.068, 0.117, 0.071, 0.044, 0.57 ,\n",
       "       0.172, 0.275, 0.093, 0.166, 0.041, 0.182, 0.121, 0.052, 0.057,\n",
       "       0.058, 0.087, 0.325, 0.293, 0.191, 0.092, 0.131, 0.012, 0.153,\n",
       "       0.055, 0.086, 0.058, 0.037, 0.143, 0.474, 0.255, 0.133, 0.072,\n",
       "       0.144, 0.032, 0.183, 0.048, 0.029, 0.071, 0.016, 0.114, 0.117,\n",
       "       0.197, 0.154, 0.132, 0.178, 0.015, 0.136, 0.049, 0.09 , 0.444,\n",
       "       0.115, 0.045, 0.767, 0.295, 0.313, 0.067, 0.137, 0.069, 0.172,\n",
       "       0.045, 0.08 , 0.126, 0.058, 0.181, 0.155, 0.223, 0.133, 0.035,\n",
       "       0.069, 0.068, 0.169, 0.019, 0.041, 0.109, 0.026, 0.2  , 0.356,\n",
       "       0.265, 0.07 , 0.027, 0.125, 0.029, 0.057, 0.021, 0.073, 0.093,\n",
       "       0.097, 0.078, 0.309, 0.294, 0.061, 0.04 , 0.376, 0.067, 0.129,\n",
       "       0.05 , 0.038, 0.299, 0.041, 0.113, 0.314, 0.179, 0.103, 0.117,\n",
       "       0.102, 0.028, 0.155, 0.02 , 0.041, 0.061, 0.076, 0.044, 0.249,\n",
       "       0.305, 0.11 , 0.016, 0.049, 0.035, 0.366, 0.024, 0.049, 0.083,\n",
       "       0.092, 0.138, 0.669, 0.191, 0.092, 0.048, 0.147, 0.025, 0.087,\n",
       "       0.032, 0.054, 0.122, 0.031, 0.233, 0.695, 0.203, 0.091, 0.132,\n",
       "       0.066, 0.012, 0.044, 0.04 , 0.043, 0.092, 0.057, 0.229, 0.333,\n",
       "       0.174, 0.225, 0.036, 0.078, 0.055, 0.011, 0.081, 0.508, 0.124,\n",
       "       0.053, 0.092, 0.207, 0.307, 0.031, 0.01 , 0.116, 0.124, 0.041,\n",
       "       0.052, 0.082, 0.031, 0.081, 0.032, 0.049, 0.068, 0.089, 0.151,\n",
       "       0.068, 0.157, 0.038, 0.209, 0.042, 0.127, 0.169, 0.15 , 0.066,\n",
       "       0.093, 0.121, 0.095, 0.118, 0.032, 0.267, 0.163, 0.156, 0.041,\n",
       "       0.078, 0.114, 0.125, 0.037, 0.025])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.04953069e+04, 1.54446468e+01, 7.68537563e+08, 4.64179097e+01,\n",
       "       1.17943031e+01, 1.32775386e+06, 3.92510770e+13, 7.94921576e+05,\n",
       "       1.12692035e+06, 1.62144747e+08])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A._IM_dict['pgv'][0].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.07982657e+24, 6.90461764e+26, 2.87230796e+21, 7.15360111e+21,\n",
       "       3.83480013e+27, 4.75959319e+16, 6.26775562e+08, 8.36034010e+40,\n",
       "       7.50372644e+18, 6.36109778e+20, 3.36055224e+27, 4.84709747e+13,\n",
       "       7.89586718e+36, 1.37944308e+32, 3.98535079e+23, 1.01316168e+16,\n",
       "       2.30312051e+31, 2.53310714e+31, 9.63145089e+22, 1.05727860e+17])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A._DM_dict['rr_pgv']['method1']['output'].data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3752658197334042e+222"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(A._IM_dict['pgv'][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseDir = r'C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites\\gm_10000yr_allsites_ask14_4samp_pgv_const_sigma'\n",
    "listDir = os.listdir(baseDir)\n",
    "n_decimals = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_i in listDir:\n",
    "# dir_i = listDir[0]\n",
    "    listFile = []\n",
    "    listFile = os.listdir(os.path.join(baseDir,dir_i))\n",
    "    for file in listFile:\n",
    "    # file = listFile[0]\n",
    "#         sparse_mat = sparse.load_npz(os.path.join(baseDir,dir_i,file)).log1p()\n",
    "#         sparse_mat.data = np.round(sparse_mat.data,decimals=n_decimals)\n",
    "#         sparse.save_npz(os.path.join(baseDir,dir_i,file),sparse_mat)\n",
    "        #     sparse_mat = A._IM_dict[im][samp_i].log1p().tocsc()\n",
    "        #     sparse_mat.data = np.round(sparse_mat.data,decimals=n_decimals)\n",
    "        #     sparse.save_npz(os.path.join(im_dir,rup_group,'pgv_samp_'+str(samp_i)+'.npz'),sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.391, 1.335, 3.066, 1.581, 1.267, 2.715, 3.475, 2.68 , 2.704,\n",
       "       2.991, 2.561, 1.707, 1.192, 2.015, 0.897, 2.835, 1.21 , 1.821,\n",
       "       3.571, 3.018, 3.318, 2.349, 3.079, 2.835, 1.94 , 1.554, 2.309,\n",
       "       1.409, 2.426, 1.557, 1.964, 2.77 , 2.584, 2.208, 3.093, 3.315,\n",
       "       2.633, 1.613, 1.754, 3.049, 1.207, 3.036, 1.467, 1.395, 2.468,\n",
       "       1.811, 1.936, 2.535, 3.787, 2.188, 1.666, 2.145, 3.275, 1.593,\n",
       "       2.205, 1.462, 1.95 , 2.981, 2.534, 3.329, 2.947, 3.664, 2.847,\n",
       "       2.143, 1.128, 2.371, 0.928, 2.321, 1.67 , 2.07 , 1.801, 3.34 ,\n",
       "       2.332, 2.588, 2.51 , 2.104, 1.319, 1.703, 2.391, 0.976, 3.008,\n",
       "       1.454, 1.367, 2.692, 2.899, 2.474, 2.226, 2.933, 2.493, 1.902,\n",
       "       1.901, 2.883, 0.934, 2.667, 1.387, 1.725, 2.704, 2.295, 2.766,\n",
       "       2.827])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat.data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = sparse.load_npz(r'C:\\Users\\barry\\Desktop\\CEC\\OpenSRA_local\\10000yr_allsites\\gm_10000yr_allsites_ask14_4samp\\0_99\\pgv_samp_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x123316 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1460753 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.709, 1.162, 3.228, 0.998, 1.947, 2.518, 2.425, 3.267, 3.678,\n",
       "       3.051, 2.716, 2.096, 2.47 , 3.066, 1.581, 2.92 , 1.24 , 2.752,\n",
       "       2.66 , 2.223, 2.975, 3.492, 2.735, 2.189, 1.621, 1.537, 4.077,\n",
       "       1.854, 3.069, 0.72 , 2.943, 3.136, 2.51 , 3.638, 2.541, 2.779,\n",
       "       3.415, 2.788, 1.959, 3.393, 1.195, 3.13 , 2.598, 2.112, 2.208,\n",
       "       1.926, 3.285, 4.089, 3.909, 3.246, 2.185, 1.08 , 2.754, 1.38 ,\n",
       "       2.58 , 1.661, 1.789, 2.201, 1.499, 2.496, 3.996, 3.331, 3.252,\n",
       "       1.81 , 2.183, 2.841, 0.923, 2.699, 1.031, 2.483, 1.233, 1.17 ,\n",
       "       2.008, 3.044, 3.075, 2.759, 1.409, 1.115, 2.684, 1.233, 2.855,\n",
       "       1.709, 2.687, 3.09 , 1.7  , 2.776, 4.659, 3.297, 3.017, 2.354,\n",
       "       1.379, 2.42 , 1.564, 2.53 , 1.39 , 2.48 , 2.422, 1.729, 2.435,\n",
       "       2.978])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aa = aa.expm1()\n",
    "aa.data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
